{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4_xVI2ibhmM"
      },
      "source": [
        "## Regression\n",
        "Teori som bliver gennemgået på klassen - [**Notion Regression**](https://www.notion.so/mercantec/Machine-Learning-e89a2baf0d414172b13d07465366482e?pvs=4#cceeafe8d5b9432d8709b1329caf6969)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "## Simpel lineær regression med syntetiske data\n",
        "\n",
        "I denne første del vil vi udforske lineær regression med en simpel database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZz29MwGgE2Y"
      },
      "source": [
        "### Læringsmål:\n",
        "\n",
        "Efter at have udført denne øvelse vil du vide, hvordan du gør følgende:\n",
        "\n",
        "  * Tilpas følgende [hyperparametre](https://developers.google.com/machine-learning/glossary/#hyperparameter):\n",
        "    * [læringsrate](https://developers.google.com/machine-learning/glossary/#learning_rate)\n",
        "    * antal [epoker](https://developers.google.com/machine-learning/glossary/#epoch)\n",
        "    * [batchstørrelse](https://developers.google.com/machine-learning/glossary/#batch_size)\n",
        "  * Tolker forskellige typer af [loss curves](https://developers.google.com/machine-learning/glossary/#loss_curve)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchnxAsaKKqO"
      },
      "source": [
        "### Importér relevante moduler\n",
        "\n",
        "Den følgende celle importerer de pakker, som programmet kræver:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9n9_cTveKmse"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIpsyJITPcbG"
      },
      "source": [
        "## Definér funktioner, der opbygger og træner en model\n",
        "\n",
        "Den følgende kode definerer to funktioner:\n",
        "\n",
        "  * `build_model(my_learning_rate)`, som opbygger en tom model.\n",
        "  * `train_model(model, feature, label, epochs)`, som træner modellen ud fra de eksempler (feature og label), du passerer.\n",
        "\n",
        "Da du ikke behøver at forstå modelopbygningskoden lige nu, har vi skjult denne kodecelle. Du kan valgfrit dobbeltklikke på overskriften for at udforske denne kode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvO_beKVP1Ke",
        "outputId": "7a193f43-e0f5-4864-9544-9e575ba84543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined build_model and train_model\n"
          ]
        }
      ],
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  # A sequential model contains one or more layers.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,\n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that\n",
        "  # TensorFlow can efficiently execute. Configure\n",
        "  # training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the feature values and the label values to the\n",
        "  # model. The model will train for the specified number\n",
        "  # of epochs, gradually learning how the feature values\n",
        "  # relate to the label values.\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the\n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Gather the history (a snapshot) of each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # Specifically gather the model's root mean\n",
        "  # squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "print(\"Defined build_model and train_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak_TMAzGOIFq"
      },
      "source": [
        "### Definér plotningsfunktioner\n",
        "\n",
        "Vi bruger en populær Python-bibliotek kaldet [Matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) til at oprette følgende to plot:\n",
        "\n",
        "* et plot af funktionens værdier vs. etiketværdierne og en linje, der viser output af den trænede model.\n",
        "* en [tabkurve](https://developers.google.com/machine-learning/glossary/#loss_curve).\n",
        "\n",
        "Vi har skjult den følgende kodecelle, fordi det ikke er relevant at lære Matplotlib i forhold til læringsmålene. Uanset det skal du stadig køre alle skjulte kodeceller."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF0BFRXTOeR3",
        "outputId": "0785b5b3-e5a2-4383-a1c2-d5d809c936ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined the plot_the_model and plot_the_loss_curve functions.\n"
          ]
        }
      ],
      "source": [
        "#@title Define the plotting functions\n",
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
        "\n",
        "  # Label the axes.\n",
        "  plt.xlabel(\"feature\")\n",
        "  plt.ylabel(\"label\")\n",
        "\n",
        "  # Plot the feature values vs. label values.\n",
        "  plt.scatter(feature, label)\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = feature[-1]\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg08C7ZdxaMe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVSDPusELEZ5"
      },
      "source": [
        "### Definér datasættet\n",
        "\n",
        "Datasættet består af 12 [eksempler](https://developers.google.com/machine-learning/glossary/#example). Hvert eksempel består af en [feature](https://developers.google.com/machine-learning/glossary/#feature) og en [label](https://developers.google.com/machine-learning/glossary/#label).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rnUSYKw4LUuh"
      },
      "outputs": [],
      "source": [
        "my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
        "my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K24afla-4s2x"
      },
      "source": [
        "### Angiv hyperparametrene\n",
        "\n",
        "Hyperparametrene i denne Colab er som følger:\n",
        "\n",
        "  * [læringsrate - learning_rate](https://developers.google.com/machine-learning/glossary/#learning_rate)\n",
        "  * [epochs](https://developers.google.com/machine-learning/glossary/#epoch)\n",
        "  * [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size)\n",
        "\n",
        "Den følgende kodecelle initialiserer disse hyperparametre og kalder derefter funktionerne, der opbygger og træner modellen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ye730h13CQ97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 654.9992 - root_mean_squared_error: 25.5930\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 641.7141 - root_mean_squared_error: 25.3321\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 632.2079 - root_mean_squared_error: 25.1437\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 624.3260 - root_mean_squared_error: 24.9865\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 617.3860 - root_mean_squared_error: 24.8473\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 611.0720 - root_mean_squared_error: 24.7199\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 605.2076 - root_mean_squared_error: 24.6010\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 599.6837 - root_mean_squared_error: 24.4884\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 594.4271 - root_mean_squared_error: 24.3809\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 589.3862 - root_mean_squared_error: 24.2773\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 1) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m my_model \u001b[38;5;241m=\u001b[39m build_model(learning_rate)\n\u001b[0;32m      6\u001b[0m trained_weight, trained_bias, epochs, rmse \u001b[38;5;241m=\u001b[39m train_model(my_model, my_feature,\n\u001b[0;32m      7\u001b[0m                                                          my_label, epochs,\n\u001b[0;32m      8\u001b[0m                                                          my_batch_size)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplot_the_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m plot_the_loss_curve(epochs, rmse)\n",
            "Cell \u001b[1;32mIn[6], line 18\u001b[0m, in \u001b[0;36mplot_the_model\u001b[1;34m(trained_weight, trained_bias, feature, label)\u001b[0m\n\u001b[0;32m     16\u001b[0m x1 \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     17\u001b[0m y1 \u001b[38;5;241m=\u001b[39m trained_bias \u001b[38;5;241m+\u001b[39m (trained_weight \u001b[38;5;241m*\u001b[39m x1)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Render the scatter plot and the red line.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:3575\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3567\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3569\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3576\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3577\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3578\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3579\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3580\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3581\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:489\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    488\u001b[0m     x \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 489\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m index_of(xy[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook.py:1358\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m-> 1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Mads\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 1) + inhomogeneous part."
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rate=0.01\n",
        "epochs=10\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwSm60H6pQjJ"
      },
      "source": [
        "### Opgave 1: Undersøg graferne\n",
        "\n",
        "Undersøg den øverste graf. De blå prikker identificerer de faktiske data, mens den røde linje identificerer output fra den trænede model. Ideelt set bør den røde linje justere sig pænt med de blå prikker. Gør den det?\n",
        "\n",
        "En vis grad af tilfældighed spiller ind i træningen af en model, så du vil få lidt forskellige resultater hver gang du træner. Det sagt, medmindre du er en ekstremt heldig person, så passer den røde linje sandsynligvis *ikke* pænt med de blå prikker.\n",
        "\n",
        "Undersøg den nederste graf, som viser tabkurven. Bemærk, at tabkurven falder, men ikke flader ud, hvilket er et tegn på, at modellen ikke er tilstrækkeligt trænet.\n",
        "\n",
        "Hvad kan have effekt på hvor godt modellen er trænet?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLXPvqCRvgI4"
      },
      "source": [
        "### Opgave 2: Øg antallet af epoker\n",
        "\n",
        "Træningstabet bør gradvist falde, først stejlt og derefter langsommere. Til sidst bør træningstab forblive stabilt (nul hældning eller næsten nul hældning), hvilket indikerer, at træningen har [konvergeret](http://developers.google.com/machine-learning/glossary/#convergence).\n",
        "\n",
        "I Opgave 1 konvergerede træningstab ikke. En mulig løsning er at øge antallet af epoker tilstrækkeligt for at få modellen til at konvergere. Det er imidlertid ineffektivt at træne ud over konvergenspunktet, så indstil ikke bare antallet af epoker til en vilkårligt høj værdi.\n",
        "\n",
        "Undersøg tabkurven. Konvergerer modellen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXuJH3h6t5qs"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "epochs= 500   # Replace ? with an integer.\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                        my_label, epochs,\n",
        "                                                        my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1tWrzP4Ww7sD"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible solution\n",
        "learning_rate=0.01\n",
        "epochs=450\n",
        "my_batch_size=12\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "# The loss curve suggests that the model does converge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KmzfFB5zwvd"
      },
      "source": [
        "### Opgave 3: Forøg læringsraten\n",
        "\n",
        "I Opgave 2 øgede du antallet af epoker for at få modellen til at konvergere. Nogle gange kan du få modellen til at konvergere hurtigere ved at øge læringsraten. Dog gør indstillingen af læringsraten for høj ofte det umuligt for en model at konvergere. I Opgave 3 har vi med vilje indstillet læringsraten for høj. Kør følgende kodecelle og se, hvad der sker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD1hTmdd0uCo"
      },
      "outputs": [],
      "source": [
        "# Increase the learning rate and decrease the number of epochs.\n",
        "learning_rate=100\n",
        "epochs=500\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c96ITm021NEV"
      },
      "source": [
        "Den resulterende model er elendig; den røde linje justerer sig ikke med de blå prikker. Desuden svinger tabkurven som en [rutsjebane](https://www.wikipedia.org/wiki/Roller_coaster). En svingende tabkurve tyder kraftigt på, at læringsraten er for høj.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r63YkMx82WVr"
      },
      "source": [
        "### Opgave 4: Find den ideelle kombination af epoker og læringsrate\n",
        "\n",
        "Tildel værdier til følgende to hyperparametre for at få træningen til at konvergere så effektivt som muligt:\n",
        "\n",
        "* Læringsrate (learning_rate)\n",
        "* Epoker (epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYC8eR5x5n4m"
      },
      "outputs": [],
      "source": [
        "# Set the learning rate and number of epochs\n",
        "learning_rate= 0.1  # Replace ? with a floating-point number\n",
        "epochs= 150   # Replace ? with an integer\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_GMGgR6O54IN"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible solution\n",
        "\n",
        "learning_rate=0.14\n",
        "epochs=70\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NDET9e6AAbA"
      },
      "source": [
        "### Opgave 5: Justér batchstørrelsen\n",
        "\n",
        "Systemet genberegner modelens tabværdi og justerer modelens vægte og bias efter hver **iteration**. Hver iteration er det interval, hvor systemet behandler én batch. For eksempel, hvis **batchstørrelsen** er 6, genberegner systemet modelens tabværdi og justerer modelens vægte og bias efter at have behandlet hver 6 eksempler.\n",
        "\n",
        "Én **epoke** dækker tilstrækkeligt mange iterationer til at behandle hver eneste eksempel i datasættet. For eksempel, hvis batchstørrelsen er 12, varer hver epoke én iteration. Men hvis batchstørrelsen er 6, kræver hver epoke to iterationer.\n",
        "\n",
        "Det er fristende blot at indstille batchstørrelsen til antallet af eksempler i datasættet (12 i dette tilfælde). Dog kan modellen faktisk trænes hurtigere på mindre batches. Omvendt indeholder meget små batches måske ikke nok information til at hjælpe modellen med at konvergere.\n",
        "\n",
        "Experimentér med `my_batch_size` i den følgende kodecelle. Hvad er det mindste heltal, du kan indstille for `my_batch_size` og stadig få modellen til at konvergere på hundrede epoker?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vGx0lOodQrT"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.05\n",
        "epochs=100\n",
        "my_batch_size= 1  # Replace ? with an integer.\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                        my_label, epochs,\n",
        "                                                        my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mtVpoBrANAm"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible solution\n",
        "\n",
        "learning_rate=0.05\n",
        "epochs=100\n",
        "my_batch_size=1 # Wow, a batch size of 1 works!\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS3q7TIF9SFL"
      },
      "source": [
        "## Sammenfatning af hyperparameter-tilpasning\n",
        "\n",
        "De fleste maskinlæringsproblemer kræver en masse hyperparameter-tilpasning. Desværre kan vi ikke give konkrete retningslinjer for tilpasning til hver model. At sænke læringsraten kan hjælpe én model med at konvergere effektivt, men få en anden model til at konvergere alt for langsomt. Du skal eksperimentere for at finde den bedste sæt hyperparametre for dit datasæt. Med det sagt er her nogle tommelfingerregler:\n",
        "\n",
        "* Træningstabet bør jævnt falde, først stejlt og derefter langsommere, indtil kurvens hældning når eller nærmer sig nul.\n",
        "* Hvis træningstabet ikke konvergerer, så træn i flere epoker.\n",
        "* Hvis træningstabet falder for langsomt, skal du øge læringsraten. Bemærk, at indstilling af læringsraten for høj også kan forhindre træningstab i at konvergere.\n",
        "* Hvis træningstabet varierer vildt (dvs. træningstabet hopper rundt), så sænk læringsraten.\n",
        "* At sænke læringsraten samtidig med at du øger antallet af epoker eller batchstørrelsen er ofte en god kombination.\n",
        "* At indstille batchstørrelsen til et *meget* lille batchnummer kan også forårsage ustabilitet. Prøv først store batchstørrelsesværdier. Derefter skal du sænke batchstørrelsen, indtil du ser forringelse.\n",
        "* For datasæt fra den virkelige verden, der består af et meget stort antal eksempler, kan hele datasættet muligvis ikke passe i hukommelsen. I sådanne tilfælde skal du reducere batchstørrelsen for at muliggøre, at en batch passer i hukommelsen.\n",
        "\n",
        "Husk: den ideelle kombination af hyperparametre afhænger af data, så du skal altid eksperimentere og verificere.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_yvxKvCbU7U"
      },
      "source": [
        "## Linear Regression with a Real Dataset\n",
        "   \n",
        "Nu prøver vi at skifter over til et reelt datasæt med huspriser i Californien.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8wtceyJj2uX"
      },
      "source": [
        "### Læringsmål:\n",
        "\n",
        "Efter at have udført denne del vil du vide, hvordan man gør følgende:\n",
        "\n",
        "  * Læse en .csv-fil ind i en [pandas](https://developers.google.com/machine-learning/glossary/#pandas) DataFrame.\n",
        "  * Undersøge et stykke [datamateriale](https://developers.google.com/machine-learning/glossary/#data_set).\n",
        "  * Eksperimentere med forskellige [funktioner](https://developers.google.com/machine-learning/glossary/#feature) i opbygningen af en model.\n",
        "  * Finjustere modellens [hyperparametre](https://developers.google.com/machine-learning/glossary/#hyperparameter).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJZEgJQSjyK4"
      },
      "source": [
        "### Datamaterialet\n",
        "\n",
        "[Datamaterialet til denne øvelse](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) er baseret på folketællingsdata fra 1990 i Californien. Datamaterialet er gammelt, men det giver stadig en fremragende mulighed for at lære om maskinlæringsprogrammering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Io78sbbU7V"
      },
      "source": [
        "### Import relevante moduler\n",
        "\n",
        "Det følgende kode er nødvendigt for at køre resten af denne filen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LdzASjKFbU7V"
      },
      "outputs": [],
      "source": [
        "#@title Import relevant modules\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "### Datamaterialet\n",
        "\n",
        "Datamateriale gemmes ofte på disken eller på en URL i [.csv-format](https://wikipedia.org/wiki/Comma-separated_values).\n",
        "\n",
        "En velformet .csv-fil indeholder kolonnenavne i den første række, efterfulgt af mange rækker med data. Et komma deler hver værdi i hver række. Her er for eksempel de første fem rækker af .csv-filen, der indeholder Californien Boligdatamaterialet:\n",
        "\n",
        "```\n",
        "\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"\n",
        "-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000\n",
        "-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000\n",
        "-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000\n",
        "-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSFQkzNlj-l6"
      },
      "source": [
        "### Indlæs .csv-filen i en pandas DataFrame\n",
        "\n",
        "Denne Colab, ligesom mange maskinlæringsprogrammer, indsamler .csv-filen og gemmer dataene i hukommelsen som en pandas Dataframe. Pandas er en open source Python-bibliotek. Den primære datetype i pandas er en DataFrame. Du kan forestille dig en pandas DataFrame som en regneark, hvor hver række er identificeret med et nummer, og hver kolonne med et navn. Pandas er selv bygget på et andet open source Python-bibliotek kaldet NumPy. Hvis du ikke er fortrolig med disse teknologier, bedes du se disse to hurtige tutorials:\n",
        "\n",
        "*   [NumPy](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb?utm_source=linearregressionreal-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=numpy_tf2-colab&hl=en)\n",
        "*   [Pandas DataFrames](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=linearregressionreal-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en)\n",
        "\n",
        "Den følgende kodecelle importerer .csv-filen i en pandas DataFrame og skalerer værdierne i labelen (`median_house_value`):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZlvdpyYKx7V"
      },
      "outputs": [],
      "source": [
        "# Import the dataset.\n",
        "training_df = pd.read_csv(filepath_or_buffer=\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "\n",
        "# Scale the label.\n",
        "training_df[\"median_house_value\"] /= 1000.0\n",
        "\n",
        "# Print the first rows of the pandas DataFrame.\n",
        "training_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5inxx49n4U9u"
      },
      "source": [
        "Skalering af `median_house_value` sætter værdien for hver bolig i tusinder af enheder. Skalering vil holde tabværdier og indlæringshastigheder i et mere venligt område.\n",
        "\n",
        "Selvom skalering af en label normalt *ikke* er afgørende, er skalering af funktioner i en multifunktionsmodel normalt *afgørende*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMysi6-3IAbu"
      },
      "source": [
        "### Undersøg datamaterialet\n",
        "\n",
        "En stor del af de fleste maskinlæringsprojekter handler om at lære dine data at kende. Pandas API giver en `describe`-funktion, der udskriver følgende statistik om hver kolonne i DataFrame:\n",
        "\n",
        "* `count`, som er antallet af rækker i den pågældende kolonne. Ideelt set indeholder `count` samme værdi for hver kolonne.\n",
        "\n",
        "* `mean` og `std`, som indeholder gennemsnittet og standardafvigelsen af værdierne i hver kolonne.\n",
        "\n",
        "* `min` og `max`, som indeholder de laveste og højeste værdier i hver kolonne.\n",
        "\n",
        "* `25%`, `50%`, `75%`, som indeholder forskellige [quantiles](https://developers.google.com/machine-learning/glossary/#quantile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_vFy_6ZbU7W"
      },
      "outputs": [],
      "source": [
        "# Get statistics on the dataset.\n",
        "training_df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9pcW_Yjtoo8"
      },
      "source": [
        "### Opgave 1: Identificer anomalier i datamaterialet\n",
        "\n",
        "Ser du nogen anomalier (mærkelige værdier) i dataene?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UoS7NWRXEs1H"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible answer.\n",
        "\n",
        "# The maximum value (max) of several columns seems very\n",
        "# high compared to the other quantiles. For example,\n",
        "# example the total_rooms column. Given the quantile\n",
        "# values (25%, 50%, and 75%), you might expect the\n",
        "# max value of total_rooms to be approximately\n",
        "# 5,000 or possibly 10,000. However, the max value\n",
        "# is actually 37,937.\n",
        "\n",
        "# When you see anomalies in a column, become more careful\n",
        "# about using that column as a feature. That said,\n",
        "# anomalies in potential features sometimes mirror\n",
        "# anomalies in the label, which could make the column\n",
        "# be (or seem to be) a powerful feature.\n",
        "# Also, as you will see later in the course, you\n",
        "# might be able to represent (pre-process) raw data\n",
        "# in order to make columns into useful features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "### Definér funktioner, der opbygger og træner en model\n",
        "\n",
        "Følgende kode definerer to funktioner:\n",
        "\n",
        "  * `build_model(my_learning_rate)`, som opbygger en tilfældigt initialiseret model.\n",
        "  * `train_model(model, feature, label, epochs)`, som træner modellen ud fra de eksempler (feature og label), du giver.\n",
        "\n",
        "Da du ikke behøver at forstå kode til opbygning af modellen lige nu, har vi skjult denne kodecelle. Du kan eventuelt dobbeltklikke på overskriften nedenfor for at se koden, der opbygger og træner en model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pedD5GhlDC-y"
      },
      "outputs": [],
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,\n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the model the feature and the label.\n",
        "  # The model will train for the specified number of epochs.\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # To track the progression of training, we're going to take a snapshot\n",
        "  # of the model's root mean squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "print(\"Defined the build_model and train_model functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndnSl7yTbU7W"
      },
      "source": [
        "### Definér plotningsfunktioner\n",
        "\n",
        "Følgende [matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) funktioner opretter følgende grafer:\n",
        "\n",
        "*  et spredningsdiagram af funktionen mod labelen og en linje, der viser output fra den trænede model.\n",
        "*  en tabkurve.\n",
        "\n",
        "Du kan eventuelt dobbeltklikke på overskriften nedenfor for at se matplotlib-koden, men bemærk, at skrivning af matplotlib-kode ikke er en vigtig del af at lære ML-programmering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VZN7O23xbU7W"
      },
      "outputs": [],
      "source": [
        "#@title Define the plotting functions\n",
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
        "\n",
        "  # Label the axes.\n",
        "  plt.xlabel(feature)\n",
        "  plt.ylabel(label)\n",
        "\n",
        "  # Create a scatter plot from 200 random points of the dataset.\n",
        "  random_examples = training_df.sample(n=200)\n",
        "  plt.scatter(random_examples[feature], random_examples[label])\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = random_examples[feature].max()\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "### Kald modelfunktionerne\n",
        "\n",
        "En vigtig del af maskinlæring er at afgøre, hvilke [funktioner](https://developers.google.com/machine-learning/glossary/#feature) der korrelerer med [labelen](https://developers.google.com/machine-learning/glossary/#label). For eksempel er modeller til forudsigelse af boligværdier i virkeligheden normalt afhængige af hundredvis af funktioner og syntetiske funktioner. Dog er denne model afhængig af kun én funktion. For nu vil du vilkårligt bruge `total_rooms` som den funktion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "nj3v5EKQFY8s"
      },
      "outputs": [],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 30\n",
        "batch_size = 30\n",
        "\n",
        "# Specify the feature and the label.\n",
        "my_feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based\n",
        "# solely on total_rooms.\n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Invoke the functions.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(my_model, training_df,\n",
        "                                         my_feature, my_label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
        "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
        "\n",
        "plot_the_model(weight, bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btp8zUNbYOcd"
      },
      "source": [
        "En vis grad af tilfældighed spiller ind i træningen af en model. Som følge heraf vil du få forskellige resultater hver gang du træner modellen. Med det sagt, givet datamaterialet og hyperparametrene, vil den trænede model generelt gøre en dårlig beskrivelse af forholdet mellem funktionen og labelen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xNqWWos_zyk"
      },
      "source": [
        "### Brug modellen til at lave forudsigelser\n",
        "\n",
        "Du kan bruge den trænede model til at lave forudsigelser. I praksis [bør du lave forudsigelser på eksempler, der ikke er blevet brugt i træning](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data). Dog vil du i denne øvelse blot arbejde med en delmængde af det samme træningsdatamateriale. En senere Colab-øvelse vil udforske måder at lave forudsigelser på eksempler, der ikke er blevet brugt i træning.\n",
        "\n",
        "Kør først følgende kode for at definere funktionen til boligforudsigelse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH63BmncAcab"
      },
      "outputs": [],
      "source": [
        "def predict_house_values(n, feature, label):\n",
        "  \"\"\"Predict house values based on a feature.\"\"\"\n",
        "\n",
        "  batch = training_df[feature][10000:10000 + n]\n",
        "  predicted_values = my_model.predict_on_batch(x=batch)\n",
        "\n",
        "  print(\"feature   label          predicted\")\n",
        "  print(\"  value   value          value\")\n",
        "  print(\"          in thousand$   in thousand$\")\n",
        "  print(\"--------------------------------------\")\n",
        "  for i in range(n):\n",
        "    print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000 + i],\n",
        "                                   training_df[label][10000 + i],\n",
        "                                   predicted_values[i][0] ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBNQujU5WjK"
      },
      "source": [
        "Nu kan du kalde boligforudsigelsesfunktionen på 10 eksempler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_0DGBt0Kz_N"
      },
      "outputs": [],
      "source": [
        "predict_house_values(10, my_feature, my_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gGaqArcpqY3"
      },
      "source": [
        "### Opgave 2: Vurder modellens forudsigelsesevne\n",
        "\n",
        "Kig på den foregående tabel. Hvor tæt er den forudsagte værdi på labelværdien? Med andre ord, forudsiger din model nøjagtigt boligværdier?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yVpjhUFm9uID"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view the answer.\n",
        "\n",
        "# Most of the predicted values differ significantly\n",
        "# from the label value, so the trained model probably\n",
        "# doesn't have much predictive power. However, the\n",
        "# first 10 examples might not be representative of\n",
        "# the rest of the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLoqis3IUPSd"
      },
      "source": [
        "### Opgave 3: Prøv en anden funktion\n",
        "\n",
        "Funktionen `total_rooms` havde kun lidt forudsigelsesevne. Ville en anden funktion have større forudsigelsesevne? Prøv at bruge `befolkning` som funktion i stedet for `total_rooms`.\n",
        "\n",
        "Bemærk: Når du ændrer funktioner, kan det være nødvendigt at ændre hyperparametrene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ab6HD4ZO75"
      },
      "outputs": [],
      "source": [
        "my_feature = \"population\"   # Replace the ? with population or possibly\n",
        "                   # a different column name.\n",
        "\n",
        "# Experiment with the hyperparameters.\n",
        "learning_rate = 2\n",
        "epochs = 3\n",
        "batch_size = 120\n",
        "\n",
        "# Don't change anything below this line.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(my_model, training_df,\n",
        "                                         my_feature, my_label,\n",
        "                                         epochs, batch_size)\n",
        "plot_the_model(weight, bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "predict_house_values(15, my_feature, my_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "107mDkW7U6mg"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible solution.\n",
        "\n",
        "my_feature = \"population\" # Pick a feature other than \"total_rooms\"\n",
        "\n",
        "# Possibly, experiment with the hyperparameters.\n",
        "learning_rate = 0.05\n",
        "epochs = 18\n",
        "batch_size = 3\n",
        "\n",
        "# Don't change anything below.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(my_model, training_df,\n",
        "                                         my_feature, my_label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "plot_the_model(weight, bias, my_feature, my_label)\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "\n",
        "predict_house_values(10, my_feature, my_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd_rHJ59AUtk"
      },
      "source": [
        "Producerede `befolkning` bedre forudsigelser end `total_rooms`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F0tPEtzcC-vK"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view the answer.\n",
        "\n",
        "# Training is not entirely deterministic, but population\n",
        "# typically converges at a slightly higher RMSE than\n",
        "# total_rooms.  So, population appears to be about\n",
        "# the same or slightly worse at making predictions\n",
        "# than total_rooms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8uYpyGacsIg"
      },
      "source": [
        "### Opgave 4: Definér en syntetisk funktion\n",
        "\n",
        "Du har fundet ud af, at hverken `total_rooms` eller `befolkning` var nyttige funktioner. Med andre ord forudsagde hverken det samlede antal værelser i et kvarter eller kvarterets befolkning med succes den medianboligværdi i det kvarter. Måske kan *forholdet* mellem `total_rooms` og `befolkning` have nogen forudsigelsesevne. Med andre ord, måske er boligtætheden relateret til medianboligværdi.\n",
        "\n",
        "For at udforske denne hypotese skal du gøre følgende:\n",
        "\n",
        "1. Opret en [syntetisk funktion](https://developers.google.com/machine-learning/glossary/#synthetic_feature), som er en ratio af `total_rooms` til `befolkning`. (Hvis du er ny inden for pandas DataFrames, så studér venligst [Pandas DataFrame Ultraquick Tutorial](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=linearregressionreal-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en).)\n",
        "2. Finjuster de tre hyperparametre.\n",
        "3. Afgør, om denne syntetiske funktion producerer en lavere tabværdi end nogen af de enkelte funktioner, du har prøvet tidligere i denne øvelse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Kx2xHSgdcpg"
      },
      "outputs": [],
      "source": [
        "# Define a synthetic feature named rooms_per_person\n",
        "training_df[\"rooms_per_person\"] = training_df[\"total_rooms\"] / training_df[\"population\"] # write your code here.\n",
        "\n",
        "# Don't change the next line.\n",
        "my_feature = \"rooms_per_person\"\n",
        "\n",
        "# Assign values to these three hyperparameters.\n",
        "learning_rate = 0.5\n",
        "epochs = 50\n",
        "batch_size = 75\n",
        "\n",
        "# Don't change anything below this line.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, rmse = train_model(my_model, training_df,\n",
        "                                         my_feature, my_label,\n",
        "                                         epochs, batch_size)\n",
        "\n",
        "plot_the_loss_curve(epochs, rmse)\n",
        "predict_house_values(15, my_feature, my_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xRfxp_3yofe3"
      },
      "outputs": [],
      "source": [
        "#@title Double-click to view a possible solution to Task 4.\n",
        "\n",
        "# Define a synthetic feature\n",
        "training_df[\"rooms_per_person\"] = training_df[\"total_rooms\"] / training_df[\"population\"]\n",
        "my_feature = \"rooms_per_person\"\n",
        "\n",
        "# Tune the hyperparameters.\n",
        "learning_rate = 0.06\n",
        "epochs = 24\n",
        "batch_size = 30\n",
        "\n",
        "# Don't change anything below this line.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, mae = train_model(my_model, training_df,\n",
        "                                        my_feature, my_label,\n",
        "                                        epochs, batch_size)\n",
        "\n",
        "plot_the_loss_curve(epochs, mae)\n",
        "predict_house_values(15, my_feature, my_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBiDWursB1Wi"
      },
      "source": [
        "Baseret på tabværdierne producerer denne syntetiske funktion en bedre model end de enkelte funktioner, du prøvede i Opgave 2 og Opgave 3. Dog skaber modellen stadig ikke de bedste forudsigelser.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEG_9oU9O54u"
      },
      "source": [
        "### Opgave 5: Find funktion(er), hvis råværdier korrelerer med labelen\n",
        "\n",
        "Indtil nu har vi støttet os til forsøg og fejl for at identificere mulige funktioner til modellen. Lad os i stedet stole på statistik.\n",
        "\n",
        "En **korrelationsmatrix** viser, hvordan hver attributs råværdier forholder sig til de andre attributters råværdier. Korrelationsværdier har følgende betydninger:\n",
        "\n",
        "  * `1.0`: perfekt positiv korrelation; det vil sige, når én attribut stiger, stiger den anden attribut.\n",
        "  * `-1.0`: perfekt negativ korrelation; det vil sige, når én attribut stiger, falder den anden attribut.\n",
        "  * `0.0`: ingen korrelation; de to kolonner [er ikke lineært relaterede](https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg).\n",
        "\n",
        "Generelt set betyder en højere absolut værdi af en korrelationsværdi, at den har større forudsigelseskraft. For eksempel indebærer en korrelationsværdi på -0,8 langt mere forudsigelseskraft end en korrelation på -0,2.\n",
        "\n",
        "Den følgende kodecelle genererer korrelationsmatricen for attributter i Californien Boligdatamaterialet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFGKL45LO8Tt"
      },
      "outputs": [],
      "source": [
        "# Generate a correlation matrix.\n",
        "training_df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp0r3NAVPEdt"
      },
      "source": [
        "Korrelationsmatricen viser ni potentielle funktioner (inklusive en syntetisk funktion) og én label (`median_house_value`). En stærk negativ korrelation eller stærk positiv korrelation med labelen tyder på en potentiel god funktion.\n",
        "\n",
        "**Din opgave:** Afgør, hvilken af de ni potentielle funktioner der ser ud til at være den bedste kandidat som funktion?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RomQTd1OPVd0"
      },
      "outputs": [],
      "source": [
        "# Median_indkomst korrelerer 0,7 med labelen\n",
        "# (median_house_value), så median_indkomst kunne være en\n",
        "# god funktion. De syv andre potentielle funktioner\n",
        "# har alle en korrelation relativt tæt på 0.\n",
        "\n",
        "# Hvis tiden tillader det, kan du prøve median_indkomst som funktion\n",
        "# og se, om modellen forbedres.\n",
        "\n",
        "my_feature = \"median_income\"\n",
        "\n",
        "# Tune the hyperparameters.\n",
        "learning_rate = 0.06\n",
        "epochs = 24\n",
        "batch_size = 30\n",
        "\n",
        "# Don't change anything below this line.\n",
        "my_model = build_model(learning_rate)\n",
        "weight, bias, epochs, mae = train_model(my_model, training_df,\n",
        "                                        my_feature, my_label,\n",
        "                                        epochs, batch_size)\n",
        "\n",
        "plot_the_loss_curve(epochs, mae)\n",
        "predict_house_values(15, my_feature, my_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RqvEbaVSlRt"
      },
      "source": [
        "Korrelationsmatricer fortæller ikke hele historien. I senere øvelser vil du finde yderligere måder at udnytte forudsigelsesevne fra potentielle funktioner.\n",
        "\n",
        "**Bemærk:** Brug af `median_indkomst` som funktion kan rejse visse etiske og retfærdighedsmæssige spørgsmål. Mod slutningen af kurset vil vi udforske etiske og retfærdighedsmæssige spørgsmål."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "azZFyENLZm_g",
        "DeKRcpe49VnV",
        "jY-QAVIhcDDR",
        "r843-s6ZcF8C"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
